# 架构设计文档

**小组名字**：UESTC_FW  
**项目名**：基于强化学习的智能游戏AI设计与实现  
**小组成员**：王科瑾，黄振洋  
**日期**：2025.7.6-2025.7.16

---

## 1. 系统架构概览

### 1.1 架构模式
本项目采用**分层架构模式**，将系统分为以下几个主要层次：
- **表示层（UI Layer）**：Pygame图形用户界面
- **应用层（Application Layer）**：游戏逻辑和AI决策
- **算法层（Algorithm Layer）**：MCTS算法和神经网络
- **数据层（Data Layer）**：模型存储和游戏状态管理

### 1.2 系统组件图
```
┌─────────────────────────────────────────────┐
│              表示层 (UI Layer)               │
├─────────────────────────────────────────────┤
│    human_play.py                           │
│    ├── GameMenu (游戏选择菜单)              │
│    ├── Game_UI (游戏界面)                   │
│    └── Human (人类玩家交互)                  │
├─────────────────────────────────────────────┤
│            应用层 (Application Layer)        │
├─────────────────────────────────────────────┤
│    game.py                                 │
│    ├── Board (棋盘状态管理)                 │
│    └── Game (游戏流程控制)                   │
├─────────────────────────────────────────────┤
│            算法层 (Algorithm Layer)          │
├─────────────────────────────────────────────┤
│    MCTS算法模块                             │
│    ├── mcts_alphaZero.py (AlphaZero MCTS)  │
│    ├── mcts_pure.py (纯MCTS)               │
│    └── TreeNode (搜索树节点)                │
│                                            │
│    神经网络模块                             │
│    ├── policy_value_net.py (Theano实现)    │
│    ├── policy_value_net_pytorch.py         │
│    ├── policy_value_net_tensorflow.py      │
│    ├── policy_value_net_keras.py           │
│    └── policy_value_net_numpy.py           │
├─────────────────────────────────────────────┤
│               训练模块                       │
├─────────────────────────────────────────────┤
│    train.py (自对弈训练流程)                │
├─────────────────────────────────────────────┤
│             数据层 (Data Layer)             │
├─────────────────────────────────────────────┤
│    模型文件                                 │
│    ├── best_policy_6_6_4.model            │
│    ├── best_policy_8_8_5.model            │
│    └── 训练数据缓存                         │
└─────────────────────────────────────────────┘
```

---

## 2. 核心组件设计

### 2.1 游戏引擎层（game.py）

#### 2.1.1 Board类
**职责**：管理棋盘状态和游戏规则
```python
class Board:
    - 棋盘状态表示（4D numpy数组）
    - 合法落子位置管理
    - 胜负判断逻辑
    - 状态转换操作
```

**核心方法**：
- `current_state()`: 返回当前棋盘的4D表示
- `do_move(move)`: 执行落子操作
- `has_a_winner()`: 判断游戏是否结束
- `game_end()`: 检查游戏终局状态

#### 2.1.2 Game类
**职责**：控制游戏流程和玩家交互
```python
class Game:
    - 玩家轮换管理
    - 游戏循环控制
    - 游戏状态监控
```

### 2.2 AI决策层

#### 2.2.1 MCTS算法架构
```
MCTS核心流程:
Selection → Expansion → Simulation → Backpropagation

TreeNode结构:
├── _parent: 父节点引用
├── _children: 子节点字典 {action: TreeNode}
├── _n_visits: 访问次数
├── _Q: 动作价值
├── _u: UCB置信上界
└── _P: 先验概率
```

**两种MCTS实现**：
1. **Pure MCTS** (`mcts_pure.py`)
   - 传统蒙特卡洛树搜索
   - 基于随机模拟的价值评估
   - 适用于基准比较

2. **AlphaZero MCTS** (`mcts_alphaZero.py`)
   - 结合神经网络的MCTS
   - 策略网络指导搜索
   - 价值网络评估叶子节点

#### 2.2.2 神经网络架构

**多框架支持设计**：
项目采用插件化架构，支持多种深度学习框架：

```
PolicyValueNet接口:
├── policy_value_net.py (Theano/Lasagne)
├── policy_value_net_pytorch.py (PyTorch)
├── policy_value_net_tensorflow.py (TensorFlow)
├── policy_value_net_keras.py (Keras)
└── policy_value_net_numpy.py (NumPy推理)
```

**网络结构**：
```
输入层: 4×H×W (4个特征平面)
    ↓
卷积层1: 32个3×3卷积核
    ↓
卷积层2: 64个3×3卷积核
    ↓
卷积层3: 128个3×3卷积核
    ↓
分支1: 策略头 (Policy Head)
├── 4个1×1卷积核
└── 全连接层 → Softmax → 动作概率分布

分支2: 价值头 (Value Head)
├── 2个1×1卷积核
├── 64个神经元全连接层
└── 1个神经元输出层 → Tanh → 状态价值
```

### 2.3 用户界面层（human_play.py）

#### 2.3.1 界面组件设计
```
GameMenu类:
├── draw_game_type_selection() - 游戏类型选择
├── draw_game_mode_selection() - 游戏模式选择
└── draw_first_player_selection() - 先手选择

Game_UI类:
├── draw() - 绘制游戏界面
├── draw_result() - 显示游戏结果
└── handle_game_end() - 处理游戏结束

Human类:
├── get_action() - 获取用户输入
└── 鼠标点击位置转换
```

#### 2.3.2 状态机设计
```
游戏状态流转:
MENU_GAME_TYPE → MENU_GAME_MODE → MENU_FIRST_PLAYER → PLAYING → GAME_END
    ↑                                                                ↓
    └─────────────────── (New Game) ←─────────────────────────────────┘
```

---

## 3. 数据流设计

### 3.1 训练数据流
```
自对弈游戏 → MCTS搜索 → 动作概率 → 训练样本
    ↓           ↓          ↓          ↓
游戏结果 → 反向传播 → 策略更新 → 模型保存
```

### 3.2 推理数据流
```
棋盘状态 → 神经网络 → (策略概率, 状态价值)
    ↓          ↓              ↓
MCTS搜索 → 动作选择 → 执行落子
```

### 3.3 用户交互数据流
```
鼠标点击 → 坐标转换 → 棋盘位置 → 合法性检查 → 执行落子
    ↓          ↓          ↓          ↓          ↓
界面更新 ← AI响应 ← AI决策 ← 状态更新 ← 回合切换
```

---

## 4. 设计模式应用

### 4.1 策略模式 (Strategy Pattern)
**应用场景**：神经网络框架选择
```python
# 不同框架的策略实现
策略接口: PolicyValueNet
具体策略: 
- TheanoStrategy (policy_value_net.py)
- PyTorchStrategy (policy_value_net_pytorch.py)
- TensorFlowStrategy (policy_value_net_tensorflow.py)
```

### 4.2 状态模式 (State Pattern)
**应用场景**：游戏界面状态管理
```python
游戏状态:
- MenuState (菜单状态)
- PlayingState (游戏进行状态)
- GameEndState (游戏结束状态)
```

### 4.3 观察者模式 (Observer Pattern)
**应用场景**：游戏状态变化通知
```python
Subject: Board (棋盘状态)
Observer: Game_UI (界面更新)
```

### 4.4 工厂模式 (Factory Pattern)
**应用场景**：AI玩家创建
```python
def create_ai_player(difficulty, model_file):
    if difficulty == "pure_mcts":
        return MCTSPlayer(c_puct=5, n_playout=1000)
    elif difficulty == "alpha_zero":
        return MCTSPlayer(policy_value_fn, c_puct=5, n_playout=400)
```

---

## 5. 性能优化设计

### 5.1 算法优化
1. **MCTS并行化**：支持多线程搜索
2. **神经网络批处理**：批量预测提高效率
3. **内存管理**：搜索树剪枝和缓存策略

### 5.2 界面优化
1. **渲染优化**：只重绘变化区域
2. **事件处理**：异步事件队列
3. **资源管理**：图像和字体缓存

### 5.3 模型优化
1. **模型压缩**：量化和剪枝
2. **推理加速**：ONNX格式转换
3. **内存优化**：模型参数共享

---

## 6. 扩展性设计

### 6.1 游戏规则扩展
- 支持不同棋盘尺寸（6×6, 8×8等）
- 支持不同连子数要求（4子棋, 5子棋等）
- 预留接口支持其他棋类游戏

### 6.2 AI算法扩展
- 模块化设计支持新的搜索算法
- 神经网络架构可配置
- 支持集成其他AI框架

### 6.3 界面功能扩展
- 多语言支持框架
- 主题和皮肤系统
- 网络对战功能预留接口

---

## 7. 安全性和可靠性

### 7.1 错误处理机制
1. **输入验证**：用户输入合法性检查
2. **异常捕获**：完善的异常处理机制
3. **状态恢复**：游戏状态一致性保证

### 7.2 数据完整性
1. **模型文件验证**：加载前完整性检查
2. **游戏状态备份**：关键状态自动保存
3. **配置文件管理**：配置参数验证

---

## 8. 部署架构

### 8.1 依赖管理
```
核心依赖:
├── Python 3.x
├── NumPy (数值计算)
├── Pygame (图形界面)
└── 深度学习框架 (可选)
    ├── Theano + Lasagne
    ├── PyTorch
    ├── TensorFlow
    └── Keras
```

### 8.2 模块化部署
- **核心模块**：game.py, mcts_*.py
- **AI模块**：policy_value_net_*.py
- **界面模块**：human_play.py
- **训练模块**：train.py

---

## 9. 总结

本项目采用了良好的分层架构设计，具有以下特点：

1. **模块化程度高**：各组件职责清晰，便于维护和扩展
2. **算法抽象合理**：MCTS和神经网络有良好的抽象设计
3. **多框架支持**：通过策略模式支持多种深度学习框架
4. **用户体验友好**：完整的GUI界面和交互设计
5. **扩展性良好**：预留了多个扩展接口

该架构设计确保了系统的可维护性、可扩展性和性能，为后续的功能扩展和优化提供了坚实的基础。
